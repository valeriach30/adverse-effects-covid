volumes:
  metadata_data: {}
  middle_var: {}
  historical_var: {}
  broker_var: {}
  coordinator_var: {}
  router_var: {}
  druid_shared: {}
  shared_data: {} # Volumen compartido para datos entre servicios

services:
  # --- Inicialización de volumen compartido ---
  volume-init:
    image: busybox:latest
    container_name: volume_init_vaers
    volumes:
      - shared_data:/opt/shared_data
    command: >
      sh -c "
      mkdir -p /opt/shared_data/vaers_results /opt/shared_data/druid_ingestion_specs &&
      chmod -R 777 /opt/shared_data &&
      echo '✅ Volumen compartido inicializado con permisos correctos'
      "
    restart: "no"

  # --- Postgres (Airflow + Superset + Druid metadata) ---
  postgres:
    container_name: postgres
    image: postgres:latest
    ports:
      - "5432:5432"
    volumes:
      - metadata_data:/var/lib/postgresql
      - ./init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    environment:
      - POSTGRES_PASSWORD=FoolishPassword
      - POSTGRES_USER=postgres
      - POSTGRES_DB=postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # --- Airflow con Polars ---
  airflow-init:
    image: "apache/airflow:2.9.0"
    container_name: airflow_init
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./dags:/opt/airflow/dags
      - ./requirements-polars.txt:/requirements.txt
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: unaclavesecretaparaelproyecto
    entrypoint: /bin/bash
    command: -c "pip install -r /requirements.txt && airflow db migrate && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin"
    restart: "no"

  # --- Airflow Webserver ---
  airflow-webserver:
    image: "apache/airflow:2.9.0"
    container_name: airflow_webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      volume-init:
        condition: service_completed_successfully
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl
      - ./superset:/opt/airflow/superset
      - ./data:/opt/airflow/data
      - ./requirements-polars.txt:/requirements.txt
      - shared_data:/opt/shared_data
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: unaclavesecretaparaelproyecto
    entrypoint: /bin/bash
    command: -c "pip install -r /requirements.txt && airflow webserver"
    restart: always
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

  # --- Airflow Scheduler ---
  airflow-scheduler:
    image: "apache/airflow:2.9.0"
    container_name: airflow_scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      volume-init:
        condition: service_completed_successfully
    volumes:
      - ./dags:/opt/airflow/dags
      - ./etl:/opt/airflow/etl
      - ./superset:/opt/airflow/superset
      - ./data:/opt/airflow/data
      - ./requirements-polars.txt:/requirements.txt
      - shared_data:/opt/shared_data
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: unaclavesecretaparaelproyecto
    entrypoint: /bin/bash
    command: -c "pip install -r /requirements.txt && airflow scheduler"
    restart: always
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

  # --- Zookeeper (requerido por Druid) ---
  zookeeper:
    container_name: zookeeper
    image: zookeeper:3.5
    ports:
      - "2181:2181"
    environment:
      - ZOO_MY_ID=1

  # --- Druid Coordinator ---
  coordinator:
    image: apache/druid:30.0.0
    container_name: coordinator
    volumes:
      - druid_shared:/opt/shared
      - coordinator_var:/opt/druid/var
      - shared_data:/opt/shared_data
    depends_on:
      - zookeeper
      - postgres
    ports:
      - "8081:8081"
    command:
      - coordinator
    env_file:
      - environment

  # --- Druid Broker ---
  broker:
    image: apache/druid:30.0.0
    container_name: broker
    volumes:
      - broker_var:/opt/druid/var
      - shared_data:/opt/shared_data
    depends_on:
      - zookeeper
      - postgres
      - coordinator
    ports:
      - "8082:8082"
    command:
      - broker
    env_file:
      - environment

  # --- Druid Historical ---
  historical:
    image: apache/druid:30.0.0
    container_name: historical
    volumes:
      - druid_shared:/opt/shared
      - historical_var:/opt/druid/var
      - shared_data:/opt/shared_data
    depends_on:
      - zookeeper
      - postgres
      - coordinator
    ports:
      - "8083:8083"
    command:
      - historical
    env_file:
      - environment

  # --- Druid MiddleManager ---
  middlemanager:
    image: apache/druid:30.0.0
    container_name: middlemanager
    volumes:
      - druid_shared:/opt/shared
      - middle_var:/opt/druid/var
      - shared_data:/opt/shared_data
    depends_on:
      - zookeeper
      - postgres
      - coordinator
    ports:
      - "8091:8091"
    command:
      - middleManager
    env_file:
      - environment

  # --- Druid Router ---
  router:
    image: apache/druid:30.0.0
    container_name: router
    volumes:
      - router_var:/opt/druid/var
      - shared_data:/opt/shared_data
    depends_on:
      - zookeeper
      - postgres
      - coordinator
      - broker
      - historical
    ports:
      - "8888:8888"
    command:
      - router
    env_file:
      - environment

  # --- Superset ---
  superset:
    image: apache/superset:4.0.0
    container_name: superset
    depends_on:
      postgres:
        condition: service_healthy
      broker:
        condition: service_started
    ports:
      - "8088:8088"
    environment:
      SUPERSET_SECRET_KEY: "unaclavesecretaparasuperset"
      SUPERSET_CONFIG_PATH: /app/superset_config.py
    volumes:
      - ./superset_config.py:/app/superset_config.py:ro
      - ./superset:/app/superset_scripts
    command: >
      /bin/bash -c "
        sleep 30 &&
        pip install psycopg2-binary pydruid &&
        superset db upgrade &&
        superset fab create-admin --username admin --firstname Admin --lastname User --email admin@example.com --password admin &&
        superset init &&
        gunicorn --bind 0.0.0.0:8088 'superset.app:create_app()'
      "
    restart: always

  # --- Servicio de monitoreo ---
  monitor:
    image: busybox:latest
    container_name: monitor
    volumes:
      - shared_data:/opt/shared_data
    command: >
      sh -c "
      echo '🔍 VAERS COVID-19 Analysis Pipeline - PRODUCTION READY'
      echo '📊 CSV → 🐻‍❄️ Polars ETL → 🐲 Druid + 🗄️ PostgreSQL → 📈 Superset'
      echo ''
      echo '🌐 Services Available:'
      echo '   - Airflow UI: http://localhost:8080 (admin/admin)'
      echo '   - Druid Console: http://localhost:8888'
      echo '   - Superset Dashboard: http://localhost:8088 (admin/admin)'
      echo '   - PostgreSQL DB: localhost:5432'
      echo ''
      echo '📁 Shared Data Directory:'
      ls -la /opt/shared_data/ 2>/dev/null || echo 'Directory not ready yet'
      echo ''
      echo '⏰ Starting continuous monitoring...'
      while true; do
        sleep 300
        echo '⏱️ $(date): All systems operational'
        if [ -d '/opt/shared_data/vaers_results' ]; then
          echo '📊 Latest Results:'
          ls -la /opt/shared_data/vaers_results/ 2>/dev/null || echo 'No results yet'
        fi
      done
      "
    restart: always
