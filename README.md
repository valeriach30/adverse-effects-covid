# An√°lisis de Efectos Adversos de Vacunas COVID-19 (VAERS)

**Autor: Valeria Chinchilla Mej√≠as**

---

## üìë Tabla de Contenidos

1. [Visi√≥n General](#-visi√≥n-general)
2. [Diagrama de Arquitectura](#Ô∏è-diagrama-de-arquitectura)
3. [Decisiones de Dise√±o](#-decisiones-de-dise√±o)
4. [Componentes del Sistema](#-componentes-del-sistema)
5. [Estructura de Archivos](#-estructura-de-archivos)
6. [Flujo de Datos](#-flujo-de-datos-detallado)
7. [C√≥mo correr el proyecto?](#-c√≥mo-correr-el-proyecto)

---

## üéØ Visi√≥n General

Este proyecto implementa un pipeline automatizado de an√°lisis de datos de farmacovigilancia utilizando tecnolog√≠as modernas de big data. El sistema procesa datos del VAERS (Vaccine Adverse Event Reporting System) relacionados con vacunas COVID-19.

### Objetivos Principales

1. **Procesamiento Eficiente**: Manejar 1.1 GB de datos CSV sin problemas de memoria
2. **Automatizaci√≥n Completa**: Pipeline totalmente autom√°tico sin intervenci√≥n manual
3. **An√°lisis Multidimensional**: Insights por fabricante, edad, geograf√≠a y s√≠ntomas
4. **Visualizaci√≥n Interactiva**: Dashboards autom√°ticos para exploraci√≥n de datos

---

## üèõÔ∏è Diagrama de Arquitectura

### Arquitectura Simplificada - Vista General

```mermaid
graph TB
    subgraph "1Ô∏è‚É£ DATOS DE ENTRADA"
        CSV[üìä Archivos CSV VAERS<br/>1.1 GB total<br/>3 archivos]
    end

    subgraph "2Ô∏è‚É£ ORQUESTACI√ìN"
        AIRFLOW[üåä Airflow<br/>Coordina todo el proceso<br/>:8080]
    end

    subgraph "3Ô∏è‚É£ PROCESAMIENTO"
        POLARS[üêª‚Äç‚ùÑÔ∏è Polars<br/>Limpia y transforma datos<br/>Procesa en bloques de 100k]
    end

    subgraph "4Ô∏è‚É£ ALMACENAMIENTO"
        DRUID[üê≤ Druid<br/>Consultas r√°pidas<br/>:8888]
        POSTGRES[üóÑÔ∏è PostgreSQL<br/>Datos relacionales<br/>]
    end

    subgraph "5Ô∏è‚É£ VISUALIZACI√ìN"
        SUPERSET[üìà Superset<br/>Dashboards interactivos<br/>:8088]
    end

    CSV --> AIRFLOW
    AIRFLOW --> POLARS
    POLARS --> DRUID
    POLARS --> POSTGRES
    DRUID --> SUPERSET
    POSTGRES --> SUPERSET

    style AIRFLOW fill:#e1f5ff
    style POLARS fill:#fff4e6
    style DRUID fill:#f3e5f5
    style POSTGRES fill:#e8f5e9
    style SUPERSET fill:#fff9c4
```

### ¬øC√≥mo Funciona el Sistema?

**El flujo es simple**:

1. **üìä Datos Entran**: Archivos CSV con reportes de efectos adversos de vacunas
2. **üåä Airflow Coordina**: Ejecuta autom√°ticamente todas las tareas en orden
3. **üêª‚Äç‚ùÑÔ∏è Polars Procesa**: Limpia, filtra y transforma los datos
4. **üíæ Se Almacenan**: Druid (para consultas r√°pidas) y PostgreSQL (para metadata)
5. **üìà Se Visualizan**: Superset crea gr√°ficos autom√°ticamente

---

### Arquitectura Detallada

<details>
<summary>Click para ver diagrama completo con todos los componentes</summary>

```mermaid
graph TB
    subgraph "üìÇ DATOS"
        CSV1[VAERSDATA.csv<br/>919 MB]
        CSV2[VAERSSYMPTOMS.csv<br/>105 MB]
        CSV3[VAERSVAX.csv<br/>80 MB]
    end

    subgraph "üåä ORQUESTACI√ìN"
        AIRFLOW[Apache Airflow<br/>13 tareas<br/>:8080]
    end

    subgraph "üêª‚Äç‚ùÑÔ∏è PROCESAMIENTO"
        POLARS[Polars ETL<br/>Chunks 100k filas]
    end

    subgraph "üíæ ALMACENAMIENTO"
        DRUID[Druid<br/>Consultas OLAP<br/>:8888]
        POSTGRES[PostgreSQL<br/>Metadata<br/>]
    end

    subgraph "üìà VISUALIZACI√ìN"
        SUPERSET[Superset<br/>4 gr√°ficos<br/>:8088]
    end

    CSV1 --> POLARS
    CSV2 --> POLARS
    CSV3 --> POLARS
    AIRFLOW -.->|Coordina| POLARS
    POLARS --> DRUID
    POLARS --> POSTGRES
    DRUID --> SUPERSET
    POSTGRES --> SUPERSET

    style AIRFLOW fill:#e1f5ff
    style POLARS fill:#fff4e6
    style DRUID fill:#f3e5f5
    style POSTGRES fill:#e8f5e9
    style SUPERSET fill:#fff9c4
```

</details>

---

## üí° Decisiones de Dise√±o

### 1. ¬øPor qu√© Polars en lugar de Apache Spark?

#### Ventajas de Polars para este proyecto

**Tama√±o del Dataset Adecuado**

- Dataset total: 1.1 GB (VAERSDATA: 919 MB, VAERSSYMPTOMS: 105 MB, VAERSVAX: 80 MB)
- Polars maneja eficientemente datasets de varios GB en memoria
- No requiere infraestructura distribuida

**Rendimiento Superior**

```python
# Polars es 5-10x m√°s r√°pido que Pandas para operaciones t√≠picas
df = pl.read_csv_batched("data.csv", batch_size=100000)  # Lectura incremental
filtered = df.filter(pl.col("VAX_TYPE").str.contains("COVID19"))  # Optimizado en Rust
```

**API Intuitiva y Debugging Simple**

- Sintaxis clara y expresiva
- Stack traces comprensibles
- No requiere configuraci√≥n de cluster

**Eficiencia de Memoria**

- Procesamiento en chunks de 100,000 filas
- Lazy evaluation con `scan_csv()` y `collect()`

**Simplicidad de Setup**

```dockerfile
# requirements-polars.txt
polars==0.20.0
# vs Spark que requiere:
# - Configuraci√≥n de JVM
# - Gesti√≥n de executors
# - Tuning de memoria complicado
```

#### Problemas Evitados con Spark

1. **Complejidad Innecesaria**: Spark requiere master, workers, executors
2. **Overhead**: Para datasets < 10 GB, el overhead de distribuci√≥n no compensa
3. **Recursos**: Spark consume significativamente m√°s RAM y CPU
4. **Debugging Dif√≠cil**: Stack traces de JVM/Scala son cr√≠pticos
5. **Dependencias Pesadas**: JVM, Hadoop, py4j, etc.

**Conclusi√≥n**: Para datasets del orden de GB (no TB), Polars ofrece mejor rendimiento con menor complejidad.

---

### 2. ¬øPor qu√© Dos Bases de Datos? (Druid + PostgreSQL)

Esta arquitectura **no es redundancia**, es **especializaci√≥n funcional**.

#### üê≤ Apache Druid - Base de Datos Columnar OLAP

**Prop√≥sito**: Consultas anal√≠ticas de alta velocidad

**Casos de Uso**:

```sql
-- Consulta t√≠pica en Druid (sub-segundo para millones de filas)
SELECT
  manufacturer,
  SUM(total_reports) AS reports,
  SUM(deaths) AS deaths
FROM vaers_symptoms_by_manufacturer
WHERE __time >= '2021-01-01'
GROUP BY manufacturer
ORDER BY reports DESC
```

**Caracter√≠sticas Clave**:

- **Almacenamiento columnar**: Solo lee columnas necesarias
- **Pre-agregaci√≥n**: M√©tricas calculadas durante ingesta
- **Particionamiento temporal**: Segmentos por d√≠a/mes
- **Compresi√≥n optimizada**: Reduce tama√±o de datos 10-100x
- **Consultas paralelas**: Distribuye carga entre nodos

**Datasets en Druid**:

1. `vaers_symptoms_by_manufacturer`: Agregaci√≥n de s√≠ntomas
2. `vaers_severity_by_age`: M√©tricas de severidad por edad
3. `vaers_geographic_distribution`: Distribuci√≥n por estado

#### üóÑÔ∏è PostgreSQL - Base de Datos Relacional

**Prop√≥sito**: Metadata operacional y datos relacionales

**Casos de Uso**:

1. **Metadata de Airflow**: Estado de DAGs, logs, ejecuciones
2. **Metadata de Superset**: Configuraci√≥n de dashboards, usuarios, permisos
3. **Datos procesados**: Tablas normalizadas para consultas ad-hoc

**Caracter√≠sticas Clave**:

- **ACID compliance**: Transacciones confiables
- **Joins complejos**: Relaciones entre tablas
- **Flexibilidad**: Schema mutable, √≠ndices configurables
- **Ecosistema maduro**: Extensiones, herramientas, soporte

**Tablas en PostgreSQL**:

```sql
-- Metadata de Airflow
airflow.dag_run
airflow.task_instance
airflow.log

-- Metadata de Superset
superset.dashboards
superset.slices (charts)
superset.tables (datasets)

-- Datos procesados (mismo contenido que Druid, diferente formato)
airflow.vaers_symptoms_analysis
airflow.vaers_severity_analysis
airflow.vaers_geographic_analysis
```

#### üîÑ Flujo de Integraci√≥n

```mermaid
graph LR
    A[Polars ETL] -->|JSON optimizado| B[Druid<br/>Consultas r√°pidas]
    A -->|CSV/SQL| C[PostgreSQL<br/>Datos relacionales]
    B -->|Conecta| D[Superset<br/>Dashboards OLAP]
    C -->|Conecta| D
    C -->|Metadata| E[Airflow]
    C -->|Metadata| F[Superset Config]
```

**¬øPor qu√© no usar solo una?**

| Criterio                         | Druid               | PostgreSQL       |
| -------------------------------- | ------------------- | ---------------- |
| Consultas agregadas (SUM, COUNT) | ‚ö° Sub-segundo      | üêå Segundos      |
| Joins complejos                  | ‚ùå Limitado         | ‚úÖ Excelente     |
| Actualizaci√≥n de registros       | ‚ùå No soportado     | ‚úÖ UPDATE/DELETE |
| Ingesta de datos                 | ‚ö° Streaming        | üêå Batch         |
| Transacciones ACID               | ‚ùå No               | ‚úÖ S√≠            |
| Almacenamiento                   | üì¶ Comprimido (10x) | üì¶ Normal        |

**Conclusi√≥n**: Druid para analytics (velocidad), PostgreSQL para metadata y relaciones (flexibilidad).

---

### 3. ¬øPor qu√© Apache Airflow para Orquestaci√≥n?

1. **DAGs Expl√≠citos**: Dependencias visuales claras
2. **Paralelizaci√≥n Autom√°tica**: Tareas independientes se ejecutan simult√°neamente
3. **Retry Policies**: Reintentos autom√°ticos ante fallos
4. **UI Integrada**: Monitoreo, logs, debugging visual
5. **Ecosistema Maduro**: 200+ operadores pre-construidos
6. **Python Nativo**: F√°cil integraci√≥n con Polars y scripts existentes

---

### 4. ¬øPor qu√© Apache Superset para Visualizaci√≥n?

**Alternativas Consideradas**: Grafana, Metabase, Tableau

**Razones para Superset**:

1. **Integraci√≥n Nativa con Druid**: Driver optimizado para consultas OLAP
2. **Configuraci√≥n Program√°tica**: API REST para automatizar dashboards

```python
# Crear dashboard mediante c√≥digo
dashboard_config = {
    "dashboard_title": "VAERS COVID-19",
    "published": True,
    "charts": [chart1_id, chart2_id, chart3_id, chart4_id]
}
```

3. **SQL Lab**: Consultas ad-hoc para exploraci√≥n
4. **Open Source**: Sin costos de licencia
5. **Extensible**: Python-based, plugins personalizables

---

## üß© Componentes del Sistema

### 1. üåä Apache Airflow - Orquestador del Pipeline

**Tareas del DAG** (13 en total):

1. **check_data_files**: Valida existencia de los CSV del VAERS
2. **setup_shared_directories**: Crea directorios de trabajo
3. **data_quality_check**: Verifica integridad de datos
4. **run_polars_etl**: Ejecuta transformaciones ETL
5. **check_druid_connectivity**: Verifica conexi√≥n a Druid
6. **prepare_druid_ingestion**: Genera specs JSON
7. **load_to_postgresql**: Carga a PostgreSQL
8. **cleanup_druid_datasources**: Limpia datos antiguos
9. **ingest_symptoms_to_druid**: Ingesta s√≠ntomas
10. **ingest_severity_to_druid**: Ingesta severidad
11. **ingest_geographic_to_druid**: Ingesta geograf√≠a
12. **refresh_superset_datasets**: Sincroniza schemas
13. **setup_superset_dashboards**: Crea visualizaciones

---

### 2. üêª‚Äç‚ùÑÔ∏è Polars - Motor ETL

**Versi√≥n**: 0.20.0

**Estrategia de Procesamiento**:

#### Lectura Incremental (Chunking)

```python
class VAERSChunkedETL:
    def __init__(self):
        self.chunk_size = 100000  # 100k filas por chunk

    def read_vaers_data_chunks(self, covid_ids: set):
        reader = pl.read_csv_batched(
            "VAERSDATA.csv",
            batch_size=self.chunk_size,
            encoding="utf8-lossy"
        )

        while True:
            chunk = reader.next_batches(1)
            if chunk is None:
                break

            # Procesar chunk inmediatamente
            processed = self.process_chunk(chunk[0], covid_ids)
            yield processed
```

**¬øPor qu√© chunks?**

- Archivo VAERSDATA.csv: 919 MB
- Cargar completo requerir√≠a ~2-3 GB RAM
- Chunks de 100k filas: ~200 MB por iteraci√≥n
- Permite procesar en m√°quinas con RAM limitada

#### Lazy Evaluation

```python
# Escanear sin cargar en memoria
covid_ids = pl.scan_csv("VAERSVAX.csv").filter(
    pl.col("VAX_TYPE").str.contains("COVID19")
).select("VAERS_ID").collect()  # Solo aqu√≠ se ejecuta la query
```

#### Transformaciones Aplicadas

**1. Filtrado de Casos COVID-19**

```python
covid_vaccines = ["COVID19", "PFIZER\\BIONTECH", "MODERNA", "JANSSEN"]
df = df.filter(
    pl.col("VAX_TYPE_CLEAN").str.contains("COVID19") |
    pl.col("VAX_MANU_CLEAN").is_in(covid_vaccines)
)
```

**2. Normalizaci√≥n de Fabricantes**

```python
df = df.with_columns([
    pl.when(pl.col("manufacturer_raw").str.contains("PFIZER|BIONTECH"))
      .then(pl.lit("PFIZER"))
    .when(pl.col("manufacturer_raw").str.contains("MODERNA"))
      .then(pl.lit("MODERNA"))
    .when(pl.col("manufacturer_raw").str.contains("JANSSEN"))
      .then(pl.lit("JANSSEN"))
    .otherwise(pl.lit("OTHER")).alias("manufacturer")
])
```

**3. Depuraci√≥n de S√≠ntomas**

```python
# Eliminar s√≠ntomas administrativos
symptoms = symptoms.filter(
    ~pl.col("symptom_raw").str.contains(
        "VACCINATION|PRODUCT QUALITY|ADMINISTRATION ERROR"
    )
)

# Eliminar s√≠ntomas inespec√≠ficos
symptoms = symptoms.filter(
    ~pl.col("symptom_raw").is_in([
        "PAIN", "FEVER", "HEADACHE", "NAUSEA", "FATIGUE"
    ])
)
```

**4. Categorizaci√≥n de Edad**

```python
df = df.with_columns([
    pl.when(pl.col("age_clean") < 18).then(pl.lit("0-17"))
    .when(pl.col("age_clean") < 30).then(pl.lit("18-29"))
    .when(pl.col("age_clean") < 40).then(pl.lit("30-39"))
    # ... m√°s categor√≠as
    .otherwise(pl.lit("80+")).alias("age_group")
])
```

**5. C√°lculo de M√©tricas**

```python
severity_analysis = df.group_by(["age_group", "manufacturer"]).agg([
    pl.len().alias("total_cases"),
    pl.sum("died_flag").alias("deaths"),
    pl.sum("hospital_flag").alias("hospitalizations"),
    pl.mean("age_clean").alias("avg_age"),
    (pl.sum("died_flag") / pl.len()).alias("death_rate"),
    (pl.sum("hospital_flag") / pl.len()).alias("hospital_rate")
])
```

---

### 3. üê≤ Apache Druid - Base de Datos Columnar

**Arquitectura Distribuida**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Cliente (Superset)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ SQL Query
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Router (Puerto 8888)                         ‚îÇ
‚îÇ         ‚Ä¢ Punto de entrada √∫nico                     ‚îÇ
‚îÇ         ‚Ä¢ Enrutamiento de consultas                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Broker (Puerto 8082)                         ‚îÇ
‚îÇ         ‚Ä¢ Recibe consultas SQL/JSON                  ‚îÇ
‚îÇ         ‚Ä¢ Planifica ejecuci√≥n distribuida            ‚îÇ
‚îÇ         ‚Ä¢ Combina resultados                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                      ‚îÇ
           ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Historical     ‚îÇ    ‚îÇ   Historical     ‚îÇ
‚îÇ   ‚Ä¢ Segmentos    ‚îÇ    ‚îÇ   ‚Ä¢ Segmentos    ‚îÇ
‚îÇ     antiguos     ‚îÇ    ‚îÇ     recientes    ‚îÇ
‚îÇ   ‚Ä¢ Datos        ‚îÇ    ‚îÇ   ‚Ä¢ Cache en     ‚îÇ
‚îÇ     en disco     ‚îÇ    ‚îÇ     memoria      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚ñ≤
           ‚îÇ
           ‚îÇ Carga de segmentos
           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Coordinator                                   ‚îÇ
‚îÇ         ‚Ä¢ Gestiona segmentos                         ‚îÇ
‚îÇ         ‚Ä¢ Balancea carga                             ‚îÇ
‚îÇ         ‚Ä¢ Pol√≠ticas de retenci√≥n                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îÇ Creaci√≥n de segmentos
                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         MiddleManager                                 ‚îÇ
‚îÇ         ‚Ä¢ Recibe tareas de ingesta                   ‚îÇ
‚îÇ         ‚Ä¢ Crea segmentos desde JSON                  ‚îÇ
‚îÇ         ‚Ä¢ Publica a deep storage                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Especificaci√≥n de Ingesta**:

```json
{
  "type": "index_parallel",
  "spec": {
    "dataSchema": {
      "dataSource": "vaers_symptoms_by_manufacturer",
      "timestampSpec": {
        "column": "__time",
        "format": "iso"
      },
      "dimensionsSpec": {
        "dimensions": ["manufacturer", "symptom"]
      },
      "metricsSpec": [
        {
          "name": "total_reports",
          "type": "longSum",
          "fieldName": "total_reports"
        },
        { "name": "deaths", "type": "longSum", "fieldName": "deaths" }
      ],
      "granularitySpec": {
        "segmentGranularity": "DAY",
        "queryGranularity": "NONE"
      }
    },
    "ioConfig": {
      "type": "index_parallel",
      "inputSource": {
        "type": "local",
        "baseDir": "/opt/shared_data/vaers_results",
        "filter": "chunked_symptoms_for_druid.json"
      },
      "inputFormat": { "type": "json" }
    }
  }
}
```

**Ventajas del Dise√±o**:

- **Inmutabilidad**: Segmentos son write-once
- **Compresi√≥n**: Datos se comprimen ~10x
- **√çndices**: Bitmap indexes para filtros r√°pidos
- **Paralelizaci√≥n**: Queries distribuidas autom√°ticamente

---

### 4. üìà Apache Superset - Plataforma de Visualizaci√≥n

**Configuraci√≥n Program√°tica**:

```python
# superset/dashboard_setup.py
def build_complete_vaers_dashboard():
    # 1. Autenticaci√≥n
    login_response = requests.post(
        f"{base_url}/api/v1/security/login",
        json={"username": "admin", "password": "admin"}
    )
    access_token = login_response.json()["access_token"]

    # 2. Crear dashboard
    dashboard = requests.post(
        f"{base_url}/api/v1/dashboard/",
        headers={"Authorization": f"Bearer {access_token}"},
        json={"dashboard_title": "VAERS COVID-19", "published": True}
    )
    dashboard_id = dashboard.json()["id"]

    # 3. Crear gr√°ficos
    charts = []
    for chart_config in chart_configs:
        chart = requests.post(
            f"{base_url}/api/v1/chart/",
            json={
                "slice_name": chart_config["name"],
                "datasource_id": dataset_id,
                "viz_type": chart_config["type"],
                "params": json.dumps(chart_config["params"]),
                "dashboards": [dashboard_id]
            }
        )
        charts.append(chart.json()["id"])

    # 4. Actualizar layout del dashboard
    requests.put(
        f"{base_url}/api/v1/dashboard/{dashboard_id}",
        json={"position_json": generate_layout(charts)}
    )
```

**Dashboards Creados**:

1. **Gr√°fico Circular**: Distribuci√≥n por fabricante
   - Dataset: `vaers_symptoms_analysis`
   - M√©trica: `SUM(total_reports)`
2. **Gr√°fico de Barras**: Top 15 s√≠ntomas
   - Dataset: `vaers_symptoms_analysis`
   - Filtro: `row_limit: 15`
3. **Gr√°fico de Barras**: Hospitalizaciones por edad
   - Dataset: `vaers_severity_analysis`
   - M√©trica: `SUM(hospitalizations)`
4. **Gr√°fico de Barras**: Distribuci√≥n geogr√°fica
   - Dataset: `vaers_geographic_analysis`

---

## üìÅ Estructura de Archivos

```
adverse-effects-covid/
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                              # Datos de entrada (1.1 GB)
‚îÇ   ‚îú‚îÄ‚îÄ VAERSDATA.csv                     # 919 MB - Datos demogr√°ficos y severidad
‚îÇ   ‚îú‚îÄ‚îÄ VAERSSYMPTOMS.csv                # 105 MB - S√≠ntomas reportados
‚îÇ   ‚îî‚îÄ‚îÄ VAERSVAX.csv                     # 80 MB - Informaci√≥n de vacunas
‚îÇ
‚îú‚îÄ‚îÄ üåä dags/                              # Definiciones de Airflow DAGs
‚îÇ   ‚îú‚îÄ‚îÄ main_pipeline.py                 # DAG principal (13 tareas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_data_files()           #   ‚îî‚îÄ Valida archivos CSV
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setup_shared_directories()   #   ‚îî‚îÄ Crea directorios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_quality_check()         #   ‚îî‚îÄ Verifica calidad
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_polars_etl()             #   ‚îî‚îÄ Ejecuta ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prepare_druid_ingestion()    #   ‚îî‚îÄ Genera specs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleanup_druid_datasources()  #   ‚îî‚îÄ Limpia Druid
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest_*_to_druid()          #   ‚îî‚îÄ Ingesta datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ refresh_superset_datasets()  #   ‚îî‚îÄ Sincroniza schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ setup_superset_dashboards()  #   ‚îî‚îÄ Crea visualizaciones
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ helpers.py                        # Funciones auxiliares
‚îÇ       ‚îú‚îÄ‚îÄ check_required_files()        #   ‚îî‚îÄ Validaci√≥n de archivos
‚îÇ       ‚îú‚îÄ‚îÄ check_data_quality()          #   ‚îî‚îÄ Control de calidad
‚îÇ       ‚îú‚îÄ‚îÄ make_druid_spec()             #   ‚îî‚îÄ Generador de specs JSON
‚îÇ       ‚îú‚îÄ‚îÄ cleanup_druid_datasource()    #   ‚îî‚îÄ Limpieza de datos
‚îÇ       ‚îú‚îÄ‚îÄ load_to_postgresql()          #   ‚îî‚îÄ Carga a PostgreSQL
‚îÇ       ‚îî‚îÄ‚îÄ refresh_superset_datasets()   #   ‚îî‚îÄ Actualiza metadata
‚îÇ
‚îú‚îÄ‚îÄ üêª‚Äç‚ùÑÔ∏è etl/                             # Procesamiento con Polars
‚îÇ   ‚îî‚îÄ‚îÄ etl_processor.py                 # Pipeline ETL principal
‚îÇ       ‚îî‚îÄ‚îÄ class VAERSChunkedETL
‚îÇ           ‚îú‚îÄ‚îÄ get_covid_ids()          #   ‚îî‚îÄ Identifica casos COVID
‚îÇ           ‚îú‚îÄ‚îÄ read_vaers_data_chunks() #   ‚îî‚îÄ Lectura incremental
‚îÇ           ‚îú‚îÄ‚îÄ process_chunk()          #   ‚îî‚îÄ Transforma datos
‚îÇ           ‚îú‚îÄ‚îÄ clean_analysis_data()    #   ‚îî‚îÄ Limpieza y filtros
‚îÇ           ‚îî‚îÄ‚îÄ generate_analyses()      #   ‚îî‚îÄ Genera agregaciones
‚îÇ
‚îú‚îÄ‚îÄ üìà superset/                          # Scripts de visualizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_setup.py               # Creaci√≥n autom√°tica de dashboards
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_complete_vaers_dashboard()
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Autenticaci√≥n JWT        #   ‚îî‚îÄ Login API
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Crear dashboard          #   ‚îî‚îÄ POST /api/v1/dashboard
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Crear gr√°ficos (4)       #   ‚îî‚îÄ POST /api/v1/chart
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Actualizar layout        #   ‚îî‚îÄ PUT /api/v1/dashboard/{id}
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ dataset_manager.py               # Gesti√≥n de datasets
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ refresh_superset_datasets()
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Sincroniza schemas       #   ‚îî‚îÄ PUT /api/v1/dataset/{id}/refresh
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ dashboard_validator.py           # Validaci√≥n post-deployment
‚îÇ       ‚îî‚îÄ‚îÄ verify_complete_dashboard()
‚îÇ           ‚îú‚îÄ‚îÄ Verifica datasets (3)    #   ‚îî‚îÄ GET /api/v1/dataset
‚îÇ           ‚îú‚îÄ‚îÄ Verifica gr√°ficos (4)    #   ‚îî‚îÄ GET /api/v1/chart
‚îÇ           ‚îî‚îÄ‚îÄ Verifica dashboards (1)  #   ‚îî‚îÄ GET /api/v1/dashboard
‚îÇ
‚îú‚îÄ‚îÄ üê≥ Configuraci√≥n Docker
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml               # Orquestaci√≥n de 12 servicios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ volume-init                  #   ‚îî‚îÄ Inicializaci√≥n de vol√∫menes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres                     #   ‚îî‚îÄ PostgreSQL 13
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airflow-init                 #   ‚îî‚îÄ Setup de Airflow
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airflow-webserver            #   ‚îî‚îÄ UI de Airflow (8080)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ airflow-scheduler            #   ‚îî‚îÄ Ejecutor de tareas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ zookeeper                    #   ‚îî‚îÄ Coordinaci√≥n Druid
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ druid-coordinator            #   ‚îî‚îÄ Gesti√≥n de segmentos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ druid-broker                 #   ‚îî‚îÄ Distribuidor de consultas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ druid-historical             #   ‚îî‚îÄ Almacenamiento de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ druid-middlemanager          #   ‚îî‚îÄ Ingesta de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ druid-router                 #   ‚îî‚îÄ Punto de entrada (8888)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ superset                     #   ‚îî‚îÄ Visualizaciones (8088)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ requirements-polars.txt          # Dependencias Python
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ polars==0.20.0               #   ‚îî‚îÄ Motor ETL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqlalchemy==2.0.23           #   ‚îî‚îÄ ORM para PostgreSQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ psycopg2-binary==2.9.9       #   ‚îî‚îÄ Driver PostgreSQL
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requests==2.31.0             #   ‚îî‚îÄ HTTP client
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ superset_config.py               # Configuraci√≥n de Superset
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SQLALCHEMY_DATABASE_URI      #   ‚îî‚îÄ Conexi√≥n a PostgreSQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DRUID_BROKER_HOST            #   ‚îî‚îÄ Conexi√≥n a Druid
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FEATURE_FLAGS                #   ‚îî‚îÄ Funcionalidades habilitadas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CACHE_CONFIG                 #   ‚îî‚îÄ Cache en filesystem
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ init-db.sh                       # Inicializaci√≥n de bases de datos
‚îÇ       ‚îî‚îÄ‚îÄ Crea schemas y usuarios      #   ‚îî‚îÄ airflow, superset, marquez
‚îÇ
‚îú‚îÄ‚îÄ üìö Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ README.md                         # Documentaci√≥n principal
‚îÇ   ‚îú‚îÄ‚îÄ ARQUITECTURA.md                   # Este archivo (documentaci√≥n detallada)
‚îÇ
‚îî‚îÄ‚îÄ üîß Archivos de Configuraci√≥n
    ‚îú‚îÄ‚îÄ .gitignore                        # Archivos excluidos de Git
    ‚îî‚îÄ‚îÄ environment                       # Variables de entorno para Druid
```

---

## üîÑ Flujo de Datos Detallado

### Fase 1: Ingesta y Validaci√≥n

```mermaid
sequenceDiagram
    participant User
    participant Airflow
    participant FileSystem

    User->>Airflow: Trigger DAG 'main_pipeline'
    Airflow->>FileSystem: check_data_files()
    FileSystem-->>Airflow: ‚úÖ VAERSDATA.csv (919 MB)
    FileSystem-->>Airflow: ‚úÖ VAERSSYMPTOMS.csv (105 MB)
    FileSystem-->>Airflow: ‚úÖ VAERSVAX.csv (80 MB)

    Airflow->>FileSystem: setup_shared_directories()
    FileSystem-->>Airflow: ‚úÖ /opt/shared_data/vaers_results
    FileSystem-->>Airflow: ‚úÖ /opt/shared_data/druid_ingestion_specs

    Airflow->>FileSystem: data_quality_check()
    FileSystem-->>Airflow: ‚úÖ Row counts valid
    FileSystem-->>Airflow: ‚úÖ No null critical fields
```

### Fase 2: Procesamiento ETL con Polars

```mermaid
sequenceDiagram
    participant Airflow
    participant Polars
    participant CSV_Files
    participant Output

    Airflow->>Polars: run_polars_etl()

    Note over Polars: Paso 1: Identificar casos COVID
    Polars->>CSV_Files: scan_csv(VAERSVAX.csv)
    CSV_Files-->>Polars: Lazy DataFrame
    Polars->>Polars: filter(VAX_TYPE contains "COVID19")
    Polars->>Polars: collect() - Ejecutar query
    Note over Polars: Result: Set de VAERS_ID COVID

    Note over Polars: Paso 2: Lectura incremental
    loop Por cada chunk de 100k filas
        Polars->>CSV_Files: read_csv_batched(VAERSDATA.csv)
        CSV_Files-->>Polars: Chunk DataFrame
        Polars->>Polars: filter(VAERS_ID in covid_ids)
        Note over Polars: Procesar solo casos COVID

        Polars->>CSV_Files: scan_csv(VAERSSYMPTOMS.csv)
        Polars->>Polars: filter(VAERS_ID in chunk_ids)
        Polars->>Polars: Limpiar s√≠ntomas

        Polars->>CSV_Files: scan_csv(VAERSVAX.csv)
        Polars->>Polars: filter(VAERS_ID in chunk_ids)
        Polars->>Polars: Normalizar fabricantes

        Polars->>Polars: join(demographics + symptoms + manufacturers)
        Polars->>Polars: Acumular en result_data[]
    end

    Note over Polars: Paso 3: Agregaciones
    Polars->>Polars: concat(result_data) - Combinar chunks
    Polars->>Polars: group_by(manufacturer, symptom).agg()
    Polars->>Output: symptoms_analysis.csv

    Polars->>Polars: group_by(age_group, manufacturer).agg()
    Polars->>Output: severity_analysis.csv

    Polars->>Polars: group_by(state, manufacturer).agg()
    Polars->>Output: geographic_analysis.csv

    Output-->>Airflow: ‚úÖ 3 datasets generados
```

### Fase 3: Carga Paralela a Bases de Datos

```mermaid
sequenceDiagram
    participant Airflow
    participant Druid
    participant PostgreSQL
    participant Output

    par Carga a Druid
        Airflow->>Airflow: prepare_druid_ingestion()
        Airflow->>Output: symptoms_ingestion.json
        Airflow->>Output: severity_ingestion.json
        Airflow->>Output: geographic_ingestion.json

        Airflow->>Druid: check_druid_connectivity()
        Druid-->>Airflow: ‚úÖ Healthy

        Airflow->>Druid: cleanup_druid_datasources()
        Druid->>Druid: DELETE /datasources/vaers_symptoms_by_manufacturer
        Druid->>Druid: DELETE /datasources/vaers_severity_by_age
        Druid->>Druid: DELETE /datasources/vaers_geographic_distribution

        par Ingesta Paralela
            Airflow->>Druid: POST /task (symptoms_ingestion.json)
            Druid->>Druid: MiddleManager crea segmentos
            Druid->>Druid: Historical almacena segmentos

            Airflow->>Druid: POST /task (severity_ingestion.json)
            Druid->>Druid: MiddleManager crea segmentos

            Airflow->>Druid: POST /task (geographic_ingestion.json)
            Druid->>Druid: MiddleManager crea segmentos
        end
    and Carga a PostgreSQL
        Airflow->>PostgreSQL: load_to_postgresql()
        PostgreSQL->>PostgreSQL: CREATE TABLE IF NOT EXISTS vaers_symptoms_analysis
        PostgreSQL->>PostgreSQL: TRUNCATE TABLE
        PostgreSQL->>Output: COPY FROM symptoms_analysis.csv

        PostgreSQL->>PostgreSQL: CREATE TABLE vaers_severity_analysis
        PostgreSQL->>Output: COPY FROM severity_analysis.csv

        PostgreSQL->>PostgreSQL: CREATE TABLE vaers_geographic_analysis
        PostgreSQL->>Output: COPY FROM geographic_analysis.csv
    end

    Druid-->>Airflow: ‚úÖ 3 datasources ingestados
    PostgreSQL-->>Airflow: ‚úÖ 3 tablas cargadas
```

### Fase 4: Configuraci√≥n de Visualizaciones

```mermaid
sequenceDiagram
    participant Airflow
    participant Superset
    participant PostgreSQL
    participant Druid

    Airflow->>Superset: refresh_superset_datasets()

    loop Para cada dataset VAERS
        Superset->>PostgreSQL: GET schema de tabla
        PostgreSQL-->>Superset: Columnas y tipos
        Superset->>Superset: Actualizar metadata interna
    end

    Superset-->>Airflow: ‚úÖ 3 datasets sincronizados

    Airflow->>Superset: setup_superset_dashboards()

    Superset->>Superset: POST /api/v1/security/login
    Superset-->>Superset: JWT token

    Superset->>Superset: POST /api/v1/dashboard/
    Note over Superset: Crear dashboard vac√≠o
    Superset-->>Superset: dashboard_id

    loop Para cada gr√°fico (4 total)
        Superset->>Superset: POST /api/v1/chart/
        Note over Superset: Configurar tipo, dataset, m√©tricas
        Superset->>PostgreSQL: Validar dataset existe
        PostgreSQL-->>Superset: ‚úÖ Dataset v√°lido
        Superset-->>Superset: chart_id
    end

    Superset->>Superset: PUT /api/v1/dashboard/{id}
    Note over Superset: Actualizar position_json con layout

    Superset-->>Airflow: ‚úÖ Dashboard publicado

    Note over Superset,Druid: Dashboard listo para consultas
    Superset->>Druid: SELECT SUM(total_reports) FROM vaers_symptoms...
    Druid-->>Superset: Resultados en < 1 segundo
```

---

## üöÄ C√≥mo correr el proyecto

### Requisitos Previos

```bash
# Software necesario
- Docker Desktop 4.0+ (con Docker Compose v2)
- 16 GB RAM m√≠nimo (recomendado: 32 GB)
- 20 GB espacio en disco
- macOS, Linux o Windows con WSL2
```

### Paso 1: Clonar Repositorio

```bash
git clone https://github.com/valeriach30/adverse-effects-covid.git
cd adverse-effects-covid
```

### Paso 2: Iniciar Sistema

```bash
# Iniciar todos los servicios
docker compose up -d

# Verificar que todos los contenedores est√°n corriendo
docker compose ps

# Esperar a que servicios est√©n listos (~2-3 minutos)
docker compose logs -f airflow-init  # Esperar mensaje "Airflow initialized"
```

### Paso 3: Acceder a Interfaces

| Servicio      | URL                   | Credenciales  |
| ------------- | --------------------- | ------------- |
| Airflow       | http://localhost:8080 | admin / admin |
| Druid Console | http://localhost:8888 | -             |
| Superset      | http://localhost:8088 | admin / admin |

### Paso 4: Ejecutar Pipeline

Desde la interfaz web de Airflow:

1. Abrir navegador en http://localhost:8080
2. Iniciar sesi√≥n con:
   - Usuario: `admin`
   - Contrase√±a: `admin`
3. En la p√°gina principal estar√°n la lista de DAGs
4. Buscar el DAG llamado `main_pipeline`
5. Activar el DAG si est√° pausado (toggle en la columna izquierda ‚è∏Ô∏è ‚Üí ‚ñ∂Ô∏è)
6. Click en el bot√≥n **‚ñ∂Ô∏è Play** en el lado derecho del DAG
7. Seleccionar **Trigger DAG** para iniciar la ejecuci√≥n

### Paso 5: Monitorear la Ejecuci√≥n

Una vez iniciado el pipeline, se puede monitorear su progreso:

1. **Ver el progreso en tiempo real:**

   - En Airflow UI, click en el nombre del DAG `main_pipeline`
   - Hay un gr√°fico con las 13 tareas del pipeline

2. **Ver logs de una tarea espec√≠fica:**

   - Click en el cuadro de la tarea en el gr√°fico
   - Seleccionar **Log** en el men√∫ emergente
   - Se puedenn ver los logs detallados de esa tarea

3. **Tiempo estimado:** El pipeline completo tarda aproximadamente **3-4 minutos** en ejecutarse

### Paso 8: Acceder a Dashboard

```bash
# 1. Abrir Superset
open http://localhost:8088

# 2. Login con admin/admin

# 3. Buscar dashboard "VAERS COVID-19"
# Deber√≠a ver 4 visualizaciones:
#   - Gr√°fico circular de fabricantes
#   - Gr√°fico de barras de s√≠ntomas
#   - Gr√°fico de barras de hospitalizaciones
#   - Gr√°fico de barras de estados
```

---

## üìä M√©tricas de Rendimiento

### Vol√∫menes de Datos Procesados

| Dataset       | Tama√±o Original | Filas Totales | Filas Filtradas (COVID) | Reducci√≥n |
| ------------- | --------------- | ------------- | ----------------------- | --------- |
| VAERSDATA     | 919 MB          | ~1,012,894    | ~1,012,894              | 0%        |
| VAERSSYMPTOMS | 105 MB          | ~1,363,171    | ~878,257                | 35.6%     |
| VAERSVAX      | 80 MB           | ~1,073,516    | ~1,073,516              | 0%        |

### Tiempos de Ejecuci√≥n

| Tarea                     | Tiempo         | Notas                        |
| ------------------------- | -------------- | ---------------------------- |
| check_data_files          | 0.00s          | Validaci√≥n r√°pida            |
| setup_shared_directories  | 0.00s          | Setear directorios           |
| data_quality_check        | 0.09s          | Verifica integridad de datos |
| run_polars_etl            | 61.59s         | Procesa ~193 chunks          |
| check_druid_connectivity  | 0.05s          | Verifica conexi√≥n a Druid    |
| prepare_druid_ingestion   | 0.00s          | Genera 3 specs JSON          |
| load_to_postgresql        | 0.25s          | Carga 3 tablas               |
| cleanup_druid_datasources | 15.32s         | Elimina segmentos antiguos   |
| refresh_superset_datasets | 14.93s         | Sincroniza schemas           |
| setup_superset_dashboards | 30.46s         | 4 gr√°ficos via API           |
| **TOTAL**                 | **~2 minutos** | Pipeline completo            |

---

## üîÆ Futuras Mejoras

### 1. Optimizaciones de Rendimiento

- **Airflow**: Migrar a CeleryExecutor para paralelizaci√≥n real
- **Polars**: Aumentar chunk_size a 500k en m√°quinas con m√°s RAM
- **Druid**: Configurar partitioning por mes para queries m√°s r√°pidas

### 2. Nuevas Funcionalidades

- **An√°lisis Temporal**: Evoluci√≥n de reportes por mes/a√±o
- **Correlaciones**: An√°lisis de co-ocurrencia de s√≠ntomas
- **Machine Learning**: Clustering de perfiles de efectos adversos
- **Alertas**: Notificaciones cuando m√©tricas superan umbrales

### 3. Integraci√≥n con Herramientas Externas

- **Apache Kafka**: Ingesta streaming de datos en tiempo real
- **Apache Spark**: Para an√°lisis de datasets > 10 GB
- **dbt**: Transformaciones declarativas y testing de datos
- **Great Expectations**: Validaci√≥n autom√°tica de calidad de datos

---

## üìö Referencias y Recursos

### Documentaci√≥n Oficial

- [Polars User Guide](https://pola-rs.github.io/polars-book/)
- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [Apache Druid Docs](https://druid.apache.org/docs/latest/design/)
- [Apache Superset Docs](https://superset.apache.org/docs/intro)

### Dataset

- [COVID-19 World Vaccine Adverse Reactions](https://www.kaggle.com/datasets/ayushggarg/covid19-vaccine-adverse-reactions?resource=download)

---

**√öltima actualizaci√≥n**: Diciembre 2025  
**Autor**: Valeria Chinchilla Mej√≠as  
**Repositorio**: https://github.com/valeriach30/adverse-effects-covid
