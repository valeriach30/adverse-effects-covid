# AnÃ¡lisis de Efectos Adversos COVID-19 (VAERS)

**Autor: Valeria Chinchilla MejÃ­as**

## ğŸ“Š Arquitectura del Pipeline

```
ğŸ“Š CSV â†’ ğŸ»â€â„ï¸ Polars ETL â†’ ğŸ² Druid + ğŸ—„ï¸ PostgreSQL â†’ ğŸ“ˆ Superset
```

Este proyecto implementa un pipeline de anÃ¡lisis de datos VAERS (Vaccine Adverse Event Reporting System) para efectos adversos de vacunas COVID-19.

## ğŸ—ï¸ Arquitectura Completa

### Componentes principales

1. **ğŸ“‚ Datos**: Archivos CSV de VAERS (1.1 GB total)
2. **ğŸ»â€â„ï¸ Polars ETL**: Procesamiento eficiente de datos
3. **ğŸŒŠ Apache Airflow**: OrquestaciÃ³n del pipeline
4. **ğŸ² Apache Druid**: Base de datos analÃ­tica para consultas rÃ¡pidas
5. **ğŸ—„ï¸ PostgreSQL**: Base de datos relacional para Superset
6. **ğŸ“ˆ Apache Superset**: Dashboards y visualizaciones

#### ğŸš€ Â¿Por quÃ© Polars en lugar de Spark?

##### âœ… Ventajas de Polars para este proyecto

- **TamaÃ±o del dataset**: 1.1 GB es perfecto para Polars (puede manejar mucho mÃ¡s)
- **Simplicidad**: API mÃ¡s intuitiva y fÃ¡cil de debuggear
- **Performance**: Extremadamente rÃ¡pido para datasets de este tamaÃ±o
- **Recursos**: No necesita un cluster completo como Spark
- **Memoria**: Uso mÃ¡s eficiente de memoria RAM
- **ConfiguraciÃ³n**: Setup mucho mÃ¡s simple

##### âŒ Problemas que se evitan con Spark

- Complejidad de configuraciÃ³n de cluster
- Overhead innecesario para datasets < 10GB
- ConfiguraciÃ³n compleja de memoria y cores
- Dependencias Java pesadas
- Debugging mÃ¡s complicado

### Flujo de datos

```
VAERSDATA.csv (919MB)     â”€â”
VAERSSYMPTOMS.csv (105MB) â”€â”¤â”€â–º Polars ETL â”€â–º JSON â”€â–º Druid
VAERSVAX.csv (80MB)       â”€â”˜                 â””â”€â–º CSV â”€â–º PostgreSQL â”€â–º Superset
```

## ğŸ“ Estructura del Proyecto

```
adverse-effects-covid/
â”œâ”€â”€ ğŸ“Š data/                          # Datos CSV de VAERS
â”‚   â”œâ”€â”€ VAERSDATA.csv                 # Datos principales (919MB)
â”‚   â”œâ”€â”€ VAERSSYMPTOMS.csv            # SÃ­ntomas (105MB)
â”‚   â””â”€â”€ VAERSVAX.csv                 # Vacunas (80MB)
â”œâ”€â”€ ğŸ»â€â„ï¸ etl/
â”‚   â””â”€â”€ etl_processor.py             # ETL principal con Polars (chunked)
â”œâ”€â”€ ğŸŒŠ dags/
â”‚   â””â”€â”€ main_pipeline.py             # DAG principal del pipeline
â”œâ”€â”€ ğŸ“ˆ superset/                      # Scripts de Superset
â”‚   â”œâ”€â”€ dashboard_setup.py           # ConfiguraciÃ³n automÃ¡tica de dashboards
â”‚   â”œâ”€â”€ dataset_manager.py           # GestiÃ³n de datasets
â”‚   â””â”€â”€ dashboard_validator.py       # ValidaciÃ³n de dashboards
â”œâ”€â”€ ğŸ³ Docker:
â”‚   â”œâ”€â”€ docker-compose.yml           # ConfiguraciÃ³n Docker principal
â”‚   â””â”€â”€ requirements-polars.txt      # Dependencias de Polars
â””â”€â”€ ğŸ“š DocumentaciÃ³n:
    â”œâ”€â”€ README.md                    # Este archivo
```

## ğŸš€ Correr el proyecto

### 1. Iniciar docker

```bash
# Iniciar todos los servicios
docker compose up -d
```

### 2. Acceder a los servicios

- **ğŸŒŠ Airflow**: <http://localhost:8080> (admin/admin)
- **ğŸ² Druid**: <http://localhost:8888>
- **ğŸ“ˆ Superset**: <http://localhost:8088> (admin/admin)

## ğŸ“Š Charts Generados

El pipeline genera 4 tipos de anÃ¡lisis:

### 1. ğŸ”¬ Reportes por Fabricante de Vacuna

- **Objetivo**: Identificar la cantidad de reportes por marca de vacuna
- **MÃ©tricas**: Total reportes, casos Ãºnicos, muertes, hospitalizaciones, tasas
- **Archivo**: `symptoms_for_druid.json`, `symptoms_analysis.csv`

### 2. Top 15 SÃ­ntomas mÃ¡s reportados

- **Objetivo**: Analizar los sÃ­ntomas mÃ¡s reportados
- **MÃ©tricas**: Casos totales, muertes, hospitalizaciones, tasas de severidad
- **Archivo**: `symptoms_for_druid.json`, `symptoms_analysis.csv`

### 3. ğŸ“ˆ Hospitalizaciones por Grupo de Edad

- **Objetivo**: Analizar severidad de efectos adversos por edad
- **Grupos**: 0-17, 18-29, 30-49, 50-64, 65+
- **MÃ©tricas**: Casos totales, muertes, hospitalizaciones, tasas de severidad
- **Archivo**: `severity_for_druid.json`, `severity_analysis.csv`

### 4. ğŸ—ºï¸ DistribuciÃ³n GeogrÃ¡fica por Estado

- **Objetivo**: AnÃ¡lisis por estado
- **MÃ©tricas**: Reportes totales, muertes, hospitalizaciones por estado
- **Archivo**: `geographic_for_druid.json`, `geographic_analysis.csv`

## ğŸ³ Servicios Docker

### Servicios principales

- **volume-init**: Inicializa volÃºmenes compartidos
- **postgres**: Base de datos (Airflow + Superset + Druid metadata)
- **airflow-webserver/scheduler**: OrquestaciÃ³n
- **zookeeper**: CoordinaciÃ³n para Druid
- **druid-coordinator/broker/historical/middlemanager/router**: Cluster Druid
- **superset**: Dashboards y visualizaciÃ³n
- **monitor**: Monitoreo del sistema

### VolÃºmenes compartidos

- **shared_data**: Intercambio de datos entre servicios
- **metadata_data**: Base de datos PostgreSQL
- **druid_shared**: Datos compartidos de Druid

## ğŸ¯ Estado del Proyecto

### âœ… Completado

- **Pipeline completo funcionando** con Polars chunked ETL
- **Arquitectura optimizada** con procesamiento por chunks (100k filas)
- **Dashboards automÃ¡ticos** con filtros de calidad de datos
- **Limpieza de cÃ³digo** y estructura organizada
- **Datos filtrados** solo fabricantes principales (PFIZER, MODERNA, JANSSEN)
- **Estados geogrÃ¡ficos vÃ¡lidos** sin datos "US" genÃ©ricos

### ğŸ¯ MÃ©tricas del Pipeline

- **Procesamiento**: ~193 chunks en ~60 segundos
- **Datos procesados**: 1.1GB â†’ anÃ¡lisis filtrados
- **Fabricantes**: 3 principales (PFIZER: 7149, MODERNA: 6589, JANSSEN: 3621 reportes)
- **Estados**: 15 principales estados de EE.UU.
- **AutomatizaciÃ³n completa**: DAG â†’ ETL â†’ Druid â†’ Superset

### ğŸ”„ Optimizaciones Implementadas

- **Chunked processing** para manejo eficiente de memoria
- **Filtros de calidad** para sÃ­ntomas y fabricantes
- **Datos geogrÃ¡ficos realistas** con distribuciÃ³n por estados
- **ValidaciÃ³n automÃ¡tica** de datasets en Superset
- **Nomenclatura simplificada** de archivos y DAGs
